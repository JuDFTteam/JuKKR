###############################################################################
####          continuous integration setting of the JuKKR code             ####
###############################################################################

# docker image containing Developlement Tools and the current Intel compilers based on CentOS 7 with cmake
image: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/extended_intel2016

before_script:
  # set +e prevents sourced scripts from aborting if single commands fail (GitLab CI sets `-e` by default)
  - set +e && source compilervars.sh intel64 && set -e
  # set environment variables to avoind stack size issue
  - export OMP_NUM_THREADS=1
  - export OMP_STACKSIZE=1g
  - ulimit -s unlimited

stages:
  - test
  - build
  - run
  - verify

###############################################################################

test:intel:
  stage: test
  script:
    # install pip
    - curl -O https://bootstrap.pypa.io/get-pip.py
    - python get-pip.py
    - pip install numpy
    # test if dependencies are working
    - echo 'do some tests here'
    - echo 'ifort ' && which ifort
    - echo 'mpiifort ' && which mpiifort
    # needs to be implemented (tests for dependencies e.g. MPI, OpenMP, LAPACK, etc.)

###############################################################################

### 1. compile code in different versions ###
 ## 1.1 debug versions
 ## 1.2 production versions

## 1.1 debug versions ##
build:intel:debug:
  stage: build
  script:
    - mkdir build_debug && cd build_debug && cmake -DENABLE_MPI=OFF -DENABLE_OMP=OFF -DCMAKE_BUILD_TYPE=Debug .. && make -j4

build:intel:openmp_debug:
  stage: build
  script:
    - mkdir build_ompdebug && cd build_ompdebug && cmake -DENABLE_MPI=OFF -DENABLE_OMP=ON -DCMAKE_BUILD_TYPE=Debug .. && make -j4

build:intel:hybrid_debug:
  stage: build
  script:
    - mkdir build_hybriddebug && cd build_hybriddebug && cmake -DENABLE_MPI=ON -DENABLE_OMP=ON -DCMAKE_BUILD_TYPE=Debug .. && make -j4

## 1.2 production versions ##
build:intel:hybrid:
  stage: build
  script:
    # compile code
    - mkdir build && cd build && cmake .. && make -j4
    - cd ..
    - ln -s build/kkr.x
    - ln -s build/kkr.x kkr.x_hybrid
    - ln -s build/kkr.x kkr.x_omp
    - ln -s build/kkr.x kkr.x_mpi
    - ln -s build/kkr.x kkr.x_serial
    - ln -s build/kkr.x kkr.x_1_mpi
  artifacts:
    paths:
      - kkr.x
      - kkr.x_hybrid
      - kkr.x_omp
      - kkr.x_mpi
      - kkr.x_serial
      - kkr.x_1_mpi
    expire_in: 1 day

###############################################################################

### 2. run tests with compiled versions ###
 ## 2.1 simple test systems in serial
 ## 2.2 comparison serial/parallel run
 ## 2.3 special features beyond selfconsistency
 ## 2.4 integration with aiida

## 2.1 simple test systems in serial ##
run:intel:serial_1:
  stage: run
  script:
    - cd tests
    - ./run_serial.py 1
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

run:intel:serial_2:
  stage: run
  script:
    - cd tests
    - ./run_serial.py 2
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

run:intel:serial_3:
  stage: run
  script:
    - cd tests
    - ./run_serial.py 3
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

## 2.2 comparison serial/parallel run ##
run:intel:parallel_2:
  stage: run
  script:
    - cd tests
    - ./run_parallel.py 2
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

run:intel:multi_node:
  image: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-control:latest
  stage: run
  services:
     - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
       alias: c1
     - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
       alias: c2
     - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
       alias: c3
     - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
       alias: c4
  script:
    - cd tests
    - ./run_multi_node.py
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

run:intel:MPIatom_7:
  stage: run
  script:
    - cd tests
    - ./run_parallel.py -7
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days
 
run:intel:MPIenerg_8:
  stage: run
  script:
    - cd tests
    - ./run_parallel.py -8
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days
 
## 2.3 special features beyond selfconsistency ##
run:intel:Jijs_4:
  stage: run
  script:
    - cd tests
    - ./run_serial.py 4
    - ./run_parallel.py -4
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 1 day

run:intel:kkrflex_5:
  stage: run
  script:
    - cd tests
    - ./run_serial.py 5
    - ./run_parallel.py -5
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 1 day

run:intel:FERMIOUT_6:
  stage: run
  script:
    - cd tests
    - ./run_serial.py 6
    - ./run_parallel.py -6
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 1 day
 
run:intel:OPERATOR_12:
  stage: run
  script:
    - mkdir tests/test_run12_mpi_1_8 && cd tests/test_run12_mpi_1_8 && ln -s ../test_inputs/test_12_*/* . && ln -s ../../kkr.x && export OMP_NUM_THREADS=1 && mpirun -np 8 ./kkr.x | tee out_kkr
    - rm -f gmat tmat gref *for* inputcard_generated.txt
    # run calculation with impurity wavefunctions
    - rm inputcard && ln -s imp/* . &&  export OMP_NUM_THREADS=1 && mpirun -np 8 ./kkr.x | tee out_kkr
    - rm -f gmat tmat gref *for* inputcard_generated.txt && cd ../
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

run:intel:DTM_GMATLL_13:
  stage: run
  script:
    - mkdir tests/test_run13_mpi_1_8 && cd tests/test_run13_mpi_1_8 && ln -s ../test_inputs/test_13_*/* . && rm DTM GMAT && cp -r ../test_inputs/test_13_*/{DTM,GMAT} . && ln -s ../../kkr.x
    - export OMP_NUM_THREADS=1 && mpirun -np 8 ./kkr.x | tee out_kkr
    - rm -f gmat tmat gref *for* inputcard_generated.txt
    - cd DTM && pwd && ls && ls -ltr .. && mpirun -np 8 ../kkr.x | tee out_kkr
    - rm -f gmat tmat gref *for* inputcard_generated.txt
    - cd ../GMAT && mpirun -np 8 ../kkr.x | tee out_kkr
    - rm -f gmat tmat gref *for* inputcard_generated.txt && cd ../
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

run:intel:qdos_14:
  stage: run
  script:
    - cd tests
    - ./run_parallel.py -14
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

run:intel:rhoq_15:
  stage: run
  script:
    - mkdir tests/test_run15 && cd tests/test_run15 && ln -s ../test_inputs/test_15_*/* .
    - ./prepare.sh
    - ./run.sh
  artifacts:
    paths:
      - tests/test_run*
    expire_in: 2 days

## 2.4 integration with aiida ##
run:intel:aiida-kkr:
  image: iffregistry.fz-juelich.de/docker-images/aiida-kkr:latest
  stage: run
  services:
    - name: postgres:latest
      alias: db
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c1
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c2
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c3
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c4
  variables:
    POSTGRES_USER: aiida
    POSTGRES_DB: aiida_default
    POSTGRES_PASSWORD: password
  script:
    # some prepararion
    - umask 000 # needed to ensure that all subdirs created by aiida have the right permissions
    - cp kkr.x_1_mpi "${KKR_EXECUTABLE_PATH}" # copy kkr executable to correct dir
    - export C_FORCE_ROOT='true' # needed since root process executes aiida
    - verdi devel setproperty logging.celery_loglevel INFO && verdi devel setproperty logging.aiida_loglevel INFO && verdi daemon restart # restart aiida daemon with increased loglevel
    # compile latest voronoi version and add to aiida
    - git clone https://gitlab-ci-token:${CI_JOB_TOKEN}@iffgit.fz-juelich.de/kkr/voronoi.git voronoi
    - cd voronoi/prog/ && make && cd ../../
    - verdi code setup < "tests/tools/setup_voronoi_aiida.txt" 
    # finally run simple test case using kkr_scf workflow of aiida
    - tests/tools/aiida_simple_test.py
    # check some output of the calculation and export aiida database
    - verdi work report 6
    - verdi export create -n 6 -a tar.gz test_export.aiida.tar.gz
    # copy log file to include in artifacts
    - cp /root/.aiida/daemon/log/celery.log .
    - cp test_export.aiida.tar.gz /builds/kkr/aiida_run/
    - tar -zcvf aiida_run.tar.gz /builds/kkr/aiida_run/
  artifacts:
    paths:
      - aiida_run.tar.gz
      - celery.log
      - test_export.aiida.tar.gz
    expire_in: 2 day

###############################################################################

### 3. check outcome of the test runs ###

verify:intel:
  stage: verify
  script:
    # use pip to install pytest
    - pip install pytest
    # prepare and execute verification using pytest
    - cd tests
    - pytest -v --ignore=tools/aiida_simple_test.py 

verify:intel:aiida:
  image: iffregistry.fz-juelich.de/docker-images/aiida-kkr:latest
  stage: verify
  services:
    - name: postgres:latest
      alias: db
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c1
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c2
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c3
    - name: iffregistry.fz-juelich.de/docker-images/centos7-intel-compilers/slurm-daemon:latest
      alias: c4
  variables:
    POSTGRES_USER: aiida
    POSTGRES_DB: aiida_default
    POSTGRES_PASSWORD: password
  script:
    # check some output of the calculation
    - verdi import test_export.aiida.tar.gz
    - python tests/tools/aiida_check_results.py
    
###############################################################################
